# TopicModelingTA
Topic Modeling Excercise 

Understanding Topic Modeling Code Design:

•	The purpose of this project is to output the common topics that occur throughout the movie_reviews corpus. In order to do so effectively, preprocessing is used to clean up the corpus text and drive improved accuracy within the topics that are outputted. Topic modeling allows us to discover the main themes across a large collection of documents, in this case the movie_reviews corpus (Blei, 2012).
•	Up until we establish the set of documents which accesses the movie_reviews corpus, all of the code is setup to import the necessary functions. establish the display topics function, create a feature set, and develop different editable sets of topic outputs and top words to be outputted. 
•	Once the movie_reviews documents is established, the first baseline/preprocessing is executed to build an idea of the kinds of output the LDA is producing from the corpus.
•	The second form of preprocessing entails the removal of stop words to further enhance the accuracy of the output and drive deeper insights into the potential topics that can be collected from the movie_reviews corpus.
•	Before the third preprocessing occurs, a test set is analyzed to determine the efficacy of stripping accents through “ascii”. This test set demonstrates the removal of special characters that are common across the movie_reviews corpus. 
•	The third and final form of preprocessing acts as a culmination of all the tested preprocessing choices used in the previous Vectorizers. This includes the use of strip accents = ascii, removal of stop words, and the use of n-gram ranges. 
 Justification of Preprocessing Choices:
-	Baseline/Preprocessing 1 (P1)
	The initial baseline and first form of preprocessing is structure to establish an initial form of insights into the potential outputs from the movie_reviews corpus. Upon initial analysis of the corpus, it was deemed that n-gram inclusion would be necessary as many of the potential topics and words that were expected to be extracted had highly ambiguous meaning when taken out of context (Denny & Spirling, 2018). As discussed by Denny and Spirling (2018), previous research tends to use 1-, 2-, 3-grams combined as this combination often provides a reasonable compromise between longer and shorter multi-word expressions. Reviewing the movie_reviews corpus drove the understanding that such a feature is necessary as many movie titles (ex. Star Wars) and actor names (ex. Adam Sandler) require the output of at least 2 words to be taken into an accurate context. Based on this understanding, an n-gram range of 2 was established which would group words in each sentence as bigrams of 2. 
	Initially, the benefits of this this feature are not entirely visible, largely due to the presence of stop words interrupting the accurate combinations of text. When reviewing the 1st preprocessed document, tf_feature_names, common occurrences of stop words, like “and” and “is”, are prevalent across the establish strings. It is also important to note that the number of topics set to output for P1 was 5 and the number of top words set to output was 8. The reasoning behind the topics was an initial expectation of 5 common movie themes/genres was anticipated to be consistent across the documents. Such genres could include action, horror, romance, life, etc. The number of top words being set to 8 was for the purpose of getting a deeper sense of the types of output that can be expected, resulting in the setting of a somewhat higher count of outputted top words. 
-	Preprocessing 2 (P2)
	When considering the results generate by tf_feature_names/P1, it was apparent that the removal of stop words would be a necessary action, driving the motivation behind the second form of preprocessing. The removal of stop words is another common preprocessing approach, as the words considered to be “stop words” are unlikely to convey valuable information (Denny & Spirling, 2018). The results of P1 showed that not only do the stop words within the text provide little to no value, they also interrupt the generation of accurate results from the use of the n-gram range in P1. Thus, stop words are set to be removed within the vectorizer. To remain consistent with the topics outputted, P2 sets the topics to 5 once again. However, the number of top words is set to 6 rather than 8 in order to test what would occur of the number of words outputted is condensed. Upon running P2, looking inside of tf_feature_names2 showed the removal of stop words to be highly effective for two reasons. 
1)	Phrases of two were effectively combined to together providing more accurate insight into the potential topics that are prevalent within the corpus. 
2)	The removal of underscores “_” occurs. Upon review of the original set of documents, it was determined that this is likely due to the fact that stop words often preceded sets of phrases that used underscores to combine them. 
The review of the original set of documents as well as the newly generated tf_feature_names2 demonstrated the need for one more change in the preprocessing approach to improve accuracy, the removal of commonly occuring special characters. 
-	Preprocessing 3 (P3)
	As determined through P2, the removal of special characters was deemed to be necessary in an effort to improve accuracy. According to Denny & Spirling (2018), the removal of punctuation and special characters is often one of the first preprocessing choice to consider as nonletter characters are considered uninformative in many applications. Although this was not the first step taken, the lack of special character removal demonstrated its necessity when working without it in P1 and P2. In order to test the removal of these characters when using the vectorizer, a set of test documents was developed in between P2 and P3, identified as ascii_documents. This test demonstrated the efficacy of strip_accents=ascii. For the sake of my own sanity, I chose to commit to the the use of ascii rather than Unicode as ascii treats a smaller set of characters as valid and take SIGNIFICANTLY less time to process. P3 also included the use of stop word removal and the set n-gram range of 2 acting as an accumulation of the previous preprocessing attempts. Running strip accents=ascii along with stop word removal and n-gram range establishment proved to be highly effective as the results outputted were consistent with the expectations developed following the P1 and P2 runs (more on this to come in the Reasonableness section). 
	Consistent with the other preprocessing efforts, the results generated by P3 varied based on the number of topics and number of top words set to be outputted. After reconfiguring these variables and rerunning the vectorizer multiple times, it was determined that 6 topics and 1 top word would be the most informative output. As topic models are often used to organize and summarize consistencies across larger collections of documents, the output of only 1 top word was concluded to be best way to provide for easy interpretation of the topics outputted (Blei, 2012). Additionally the setting of the number of topics to 6 was for the sake of not outputting too much text while summarizing the most consistent topics detected in the corpus. 
Reasonableness 
-	The initial expectation for the topic output was to see consistent movie genres. This was not necessarily due to any evidence, but due to a preexisting knowledge of what movie reviews entailed. Although P1 and P2 showed results that could have led to the belief genre names would be outputted (ex. The use of “action” or horror”), the occurrence of actor names and movie titles was much more consistent throughout each output. Therefore, when the outputs generated by P3 consisted of movie names, genres, and actors (ex. Star Wars, sci-fi, Jackie Chan) the results came at no surprise. Movie reviews do not necessarily focus on the genre of the film, but rather an analysis of the actors and more specific components of such films. Reviewing the documents provided in the original corpus is also consistent with this understanding. Although it was not initially expected, P1 and P2 provided thorough insight into what would be expected in P3’s output, with results entailing actors, genres, and film titles to be considered highly reasonable as these were consistent elements across all of the movie reviews. 



References:

Blei, D. (2012). Probabilistic Topic Models. 

Denny, M., & Spirling, A. (2018). Text Preprocessing for Unsupervised Learning. 

